{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Score de Brier\"\n",
        "format: pdf\n",
        "editor: visual\n",
        "---"
      ],
      "id": "34ba8440"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Le score de Brier est une fonction de Score qui mesure l'exactiture des préditictions probabilistes. Pour les prédictions unidimensionnelles, elle est strictement équivalente à l'erreur quadratique moyenne aux probabilités prédites.\n",
        "\n",
        "# Définition générale :\n",
        "\n",
        "Dans le cas où une variable peut prendre plus de 2 valeurs. Le score de Brier est alors défini par : \n",
        "\n",
        "$$\n",
        "B_s = \\frac{1}{n}\\sum_{i=1}^{n}\\sum_{j=1}^{m}(p_{i,j} - o_{i,j})^2\n",
        "$$\n",
        "\n",
        "- $n$ représente le nombre total d'instances de toutes les classes (nombre de sous vecteurs)\n",
        "- $m$ représente le nombre total de classes possibles dans lesquels l'évènement peut tomber \n",
        "- $p_{i,j}$ représente la probabilité prédite pour la classe $i$ pour i $\\in [\\![1,n]\\!]$\n",
        "- $o_{i,j}$ vaut 1 si si la ième observation est de la catégorie j et 0 sinon pour j \n",
        "$\\in [\\![1,m]\\!]$\n",
        "\n",
        "Le score de Brier peut être décomposé en 3 composantes additives : incertitude, fiabilité et résolution\n",
        "\n",
        "$$\n",
        "B_s = F - R + I \n",
        "$$\n",
        "\n",
        "- I : terme d'incertitude qui prend en compte la dispersion des observations.\n",
        "\n",
        "- F : terme de fiabilité qui mesure dans quelle circonstances les probabilités prévues sont proches des probabilités réelles compte tenu d'une prévision. Si la fiabilité est de 0 la prévision est parfaitement fiable. \n",
        "Par exemple si on regroupe tous les cas où 80% de probabilité de pluie était prévue, si il a plu 4 jours sur 5 on obtient ainsi une fiabilité parfaite. \n",
        "\n",
        "- R : terme de résolution qui mesure la distance entre les probabilités d'occurence\n",
        "\n",
        "\n",
        "# Interprétation et décomposition :\n",
        "\n",
        "Plus la valeur du score de Brier sera faible plus la prédiction sera bonne et une prévision parfaite obtiendra un score de 0. A l'inverse le plus mauvais score sera de 1.\n",
        "\n",
        "Code de la fonction :\n"
      ],
      "id": "505d090a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# code de la fonction \n",
        "\n",
        "\n",
        "def brier_score_f(predictions, observations):\n",
        "    \"\"\"\n",
        "    Calcul du score de Brier.\n",
        "\n",
        "    Arguments:\n",
        "        predictions (liste de liste ou numpy array) Prédictions des probabilités pour chaque classe.\n",
        "        observations (liste de liste ou numpy arrays): Observations réelles (0 ou 1 pour chaque classe).\n",
        "\n",
        "    \"\"\"\n",
        "    n = len(predictions)\n",
        "    m = len(predictions[0])\n",
        "    bs = 0.0\n",
        "\n",
        "    for i in range(n):\n",
        "        for j in range(m):\n",
        "            bs += (predictions[i][j] - observations[i][j]) ** 2\n",
        "\n",
        "    bs /= n\n",
        "    return bs\n",
        "\n",
        "\n",
        "# Exemple : \n",
        "\n",
        "predictions = [[0.1, 0.9, 0.8, 0.3],[0.4,0.9,0.2,0.7]]\n",
        "observations = [[0, 1, 1, 0],[1,1,0,1]]\n",
        "\n",
        "bs = brier_score_f(predictions, observations)\n",
        "print(\"Score de Brier :\", bs)"
      ],
      "id": "31ae2277",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exemple pour la classification avec Iris : \n"
      ],
      "id": "c6bae061"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(metrics.confusion_matrix(attendu,prediction))"
      ],
      "id": "007cf8b0",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}